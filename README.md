# AdaTAD

[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/end-to-end-temporal-action-detection-with-1b/temporal-action-localization-on-thumos14)](https://paperswithcode.com/sota/temporal-action-localization-on-thumos14?p=end-to-end-temporal-action-detection-with-1b)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/end-to-end-temporal-action-detection-with-1b/temporal-action-localization-on-activitynet)](https://paperswithcode.com/sota/temporal-action-localization-on-activitynet?p=end-to-end-temporal-action-detection-with-1b)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/end-to-end-temporal-action-detection-with-1b/temporal-action-localization-on-epic-kitchens)](https://paperswithcode.com/sota/temporal-action-localization-on-epic-kitchens?p=end-to-end-temporal-action-detection-with-1b)


This repo holds the official pytorch implementation of paper: ["AdaTAD: End-to-End Temporal Action Detection with 1B Parameters Across 1000 Frames"](https://arxiv.org/abs/2311.17241)

## Updates
- **[2024/04/17]** AdaTAD is released at [OpenTAD](https://github.com/sming256/OpenTAD/tree/main/configs/adatad)! We achieve an average mAP of 42.90% on ActivityNet and 77.07% on THUMOS14. Please have a check!
- **[2024/03/28]** We release an open-source temporal action detection toolbox at [OpenTAD](https://github.com/sming256/OpenTAD). :boom:
- **[2024/02/28]** AdaTAD is accepted by **CVPR2024**.
